# ğŸŒ¸ ClassificaÃ§Ã£o de EspÃ©cies do Iris Dataset com SVM e Naive Bayes

Este projeto de IniciaÃ§Ã£o CientÃ­fica tem como foco a aplicaÃ§Ã£o e comparaÃ§Ã£o de algoritmos de aprendizado supervisionado no **Iris Dataset**, com Ãªnfase em mÃ©todos de prÃ©-processamento, engenharia de atributos e avaliaÃ§Ã£o de modelos.

## ğŸ§  Objetivo

Investigar a eficiÃªncia dos classificadores **Support Vector Machine (SVM)** e **Naive Bayes** (GaussianNB e BernoulliNB), utilizando mÃ©tricas quantitativas e experimentos em Python para identificar qual abordagem oferece maior desempenho e robustez para conjuntos de dados reais.

## âš™ï¸ Tecnologias Utilizadas

- Python 3.11.7  
- Jupyter Notebook  
- pandas, numpy  
- matplotlib, seaborn  
- scikit-learn  

## ğŸ“ Estrutura do Projeto

```INICIACAO_CIENTIFICA_ML_CLASSIFICAO/
â”‚
â”œâ”€â”€ artigo/                      # VersÃµes dos artigosd
â”‚   â””â”€â”€ Modelo Overleaf.pdf
â”œâ”€â”€ data/                      # Conjunto de dados processado
â”‚   â””â”€â”€ iris_processado.pkl
â”‚
â”œâ”€â”€ notebooks/                 # Notebooks Jupyter para anÃ¡lises individuais
â”‚   â”œâ”€â”€ somente_teste.ipynb
â”‚   â””â”€â”€ validacao_teste.ipynb
â”‚
â”œâ”€â”€ scripts/                   # Scripts reutilizÃ¡veis
â”‚   â”œâ”€â”€ index.py
â”‚   â”œâ”€â”€ pre_processing.py
â”‚   â””â”€â”€ treino_teste.py
â”‚
â”œâ”€â”€ venv/                      # Ambiente virtual Python (fora do controle de versÃ£o)
â”‚
â”œâ”€â”€ README.md                  # DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ requirements.txt           # Lista de dependÃªncias do projeto
â””â”€â”€ .gitignore                 # Arquivos e pastas ignoradas pelo Git
```



## ğŸ§ª Metodologia

- **PrÃ©-processamento de Dados**:
  - RemoÃ§Ã£o de outliers (IQR)
  - GeraÃ§Ã£o de novas features (Ã¡reas, proporÃ§Ãµes)
  - NormalizaÃ§Ã£o (`StandardScaler`)

- **Modelagem**:
  - ComparaÃ§Ã£o entre DummyClassifier, SVM (4 kernels) e Naive Bayes (Gaussian e Bernoulli)
  - Ajuste de hiperparÃ¢metros via `GridSearchCV`
  - AvaliaÃ§Ã£o com validaÃ§Ã£o cruzada (5 folds)

- **MÃ©trica Principal**:
  - AcurÃ¡cia mÃ©dia Â± desvio padrÃ£o

## ğŸ“Š Resultados

| Modelo                | AcurÃ¡cia ValidaÃ§Ã£o | AcurÃ¡cia Teste | ObservaÃ§Ãµes                             |
|----------------------|--------------------|----------------|-----------------------------------------|
| DummyClassifier      | 0.35               | 0.26           | Baseline (classe majoritÃ¡ria)           |
| SVM (linear)         | 0.96 Â± 0.04        | 0.96           | Melhor desempenho e robustez            |
| GaussianNB (ajustado)| 1.00               | 1.00           | PossÃ­vel overfitting (dados pequenos)   |
| BernoulliNB          | 0.82 Â± 0.05        | -              | Inferior, sensÃ­vel a distribuiÃ§Ã£o binÃ¡ria |

## ğŸ’¡ ConclusÃµes

- O `SVM` com kernel linear demonstrou ser o modelo mais **consistente e confiÃ¡vel**.
- O `GaussianNB` otimizado alcanÃ§ou alta acurÃ¡cia, mas pode estar sofrendo de overfitting devido ao tamanho reduzido do conjunto de dados.
- O prÃ©-processamento teve papel fundamental na performance dos modelos.


## Ambiente Virtual
Ative o ambiente virtual (ou crie um com venv) e instale as dependÃªncias:
```
pip install -r requirements.txt
```

## âœ¨ Autor
Bruno Dezorzi
Estudante de ADS, apaixonado por CiÃªncia de Dados, AstrofÃ­sica e IA.
Explorador de padrÃµes, movido por curiosidade e guiado por propÃ³sito.

"Sic Parvis Magna" â€” Sir Francis Drake.